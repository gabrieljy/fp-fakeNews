{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d475c27-0c4b-4564-9ff8-31df4a0992ec",
   "metadata": {},
   "source": [
    "# Importing dependencies\n",
    "\n",
    "The following code block contains all import statements for all required dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83b5826-ffe7-4e04-a054-d7202bb6aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import re\n",
    "import time\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f2b3a-a7ed-4421-ab7a-b9aaf82dee51",
   "metadata": {},
   "source": [
    "# Text Preprocessing for Transformer Models\n",
    "\n",
    "The following codeblock contains a lightweight preprocessing function that handles basic text issues (encoding, whitespace) while preserving semantic content critical for transformer-based models. \n",
    "\n",
    "Unlike traditional NLP preprocessing that heavily modifies text (through stemming, lemmatisation, stopword removal, etc.), this approach is deliberately minimalistic to retain stylistic elements and contextual information that transformer models can leverage for better classification performance. The reasons for this design choice are:\n",
    "1. Transformer models (e.g. MobileBERT) are pre-trained on raw, unprocessed text with all variations intact, meaning it has already learned relationships between word forms (e.g. 'run' vs. running').\n",
    "2. Word forms, tenses, writing style, etc. can be important context clues in fake news detection and stemming may remove these contextual details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cff5c2b-6c39-4a5e-b22b-8cbb00b95061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2.5 step2\n",
    "\n",
    "# function to perform minimal text preprocessing for transformer models\n",
    "# arguments:\n",
    "# text - input text to preprocess (string)\n",
    "# max_length - maximum number of words to keep (default: 512)\n",
    "#\n",
    "# returns preprocessed text string\n",
    "def preprocess_text(text, max_length=512):\n",
    "    # step 1: handle edge cases\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # step 2: clean encoding issues\n",
    "    # remove non-ascii characters that could cause problems\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # step 3: normalize text format\n",
    "    # replace multiple whitespace characters with single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # step 4: truncate oversized inputs\n",
    "    # transformer models have context length limits\n",
    "    words = text.split()\n",
    "    if len(words) > max_length:\n",
    "        text = ' '.join(words[:max_length])\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795707e-7157-49b0-b515-8cb475418305",
   "metadata": {},
   "source": [
    "# LIAR and ISOT Dataset Processing Modules\n",
    "\n",
    "The following codeblock handles the loading and preprocessing of the LIAR dataset, which contains political statements with varying degrees of truthfulness:\n",
    "\n",
    "1. Column Definition - Sets up the structure for the TSV data, including fields for statement, speaker, context, and truthfulness metrics.\n",
    "2. Data Loading - Reads the train, validation, and test sets with appropriate column mapping.\n",
    "3. Label Binarization - Converts the 6-point truthfulness scale into a binary classification task:\n",
    "    - 'pants-fire', 'false', and 'barely-true' → fake (0)\n",
    "    - 'half-true', 'mostly-true', and 'true' → real (1)\n",
    "4. Source Tracking - Tags all entries as originating from the 'liar' dataset to enable source-specific evaluation later.\n",
    "\n",
    "This preprocessing maintains the rich metadata available in LIAR while standardizing the label format for binary classification.\n",
    "\n",
    "It will also manage the loading and preprocessing of the ISOT dataset, which contains full news articles labeled as real or fake:\n",
    "\n",
    "1. Data Acquisition - Loads separately stored fake and real news articles from CSV files.\n",
    "2. Binary Labeling - Assigns clear binary labels (0 for fake, 1 for real) to each article.\n",
    "3. Source Identification - Tags all entries as originating from the 'isot' dataset for later analysis.\n",
    "4. Text Consolidation - Combines article titles with full text to create a comprehensive 'statement' field that parallels the LIAR dataset structure.\n",
    "5. Data Preparation - Performs concatenation, shuffling, and train/validation/test splitting with configurable proportions.\n",
    "\n",
    "This preprocessing creates standardized data splits that maintain the same structure as the LIAR dataset, enabling unified handling in downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a50de3-170a-4c9f-91eb-cd39e5ee0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module for loading and preprocessing LIAR dataset\n",
    "# arguments:\n",
    "# train_path, valid_path, test_path - paths to LIAR dataset files\n",
    "# return - tuple of (train_df, valid_df, test_df) with preprocessed data\n",
    "def load_liar_dataset(train_path, valid_path, test_path):\n",
    "    # step 1: define column names for LIAR dataset\n",
    "    column_names = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', \n",
    "                   'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', \n",
    "                   'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
    "    \n",
    "    # step 2: load datasets\n",
    "    train_df = pd.read_csv(train_path, sep='\\t', names=column_names)\n",
    "    valid_df = pd.read_csv(valid_path, sep='\\t', names=column_names)\n",
    "    test_df = pd.read_csv(test_path, sep='\\t', names=column_names)\n",
    "    \n",
    "    # step 3: convert labels to binary (0 for fake, 1 for real)\n",
    "    # map 'pants-fire', 'false', 'barely-true' to fake (0)\n",
    "    # map 'half-true', 'mostly-true', 'true' to real (1)\n",
    "    label_map = {\n",
    "        'pants-fire': 0, 'false': 0, 'barely-true': 0,\n",
    "        'half-true': 1, 'mostly-true': 1, 'true': 1\n",
    "    }\n",
    "    \n",
    "    # apply mapping to each dataset\n",
    "    train_df['label'] = train_df['label'].map(label_map)\n",
    "    valid_df['label'] = valid_df['label'].map(label_map)\n",
    "    test_df['label'] = test_df['label'].map(label_map)\n",
    "    \n",
    "    # step 4: add source identifier\n",
    "    train_df['source'] = 'liar'\n",
    "    valid_df['source'] = 'liar'\n",
    "    test_df['source'] = 'liar'\n",
    "    \n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "# module for loading and preprocessing ISOT dataset\n",
    "# arguments:\n",
    "# fake_path - path to Fake.csv\n",
    "# real_path - path to Real.csv\n",
    "# test_split - fraction of data to use for testing (default: 0.2)\n",
    "# valid_split - fraction of data to use for validation (default: 0.1)\n",
    "# return - tuple of (train_df, valid_df, test_df) with preprocessed data\n",
    "def load_isot_dataset(fake_path, real_path, test_split=0.2, valid_split=0.1):\n",
    "    # step 1: load fake and real news\n",
    "    fake_df = pd.read_csv(fake_path)\n",
    "    real_df = pd.read_csv(real_path)\n",
    "    \n",
    "    # step 2: add binary labels (0 for fake, 1 for real)\n",
    "    fake_df['label'] = 0\n",
    "    real_df['label'] = 1\n",
    "    \n",
    "    # step 3: add source identifier\n",
    "    fake_df['source'] = 'isot'\n",
    "    real_df['source'] = 'isot'\n",
    "    \n",
    "    # step 4: combine text and title for ISOT dataset\n",
    "    fake_df['statement'] = fake_df['title'] + \" \" + fake_df['text'] \n",
    "    real_df['statement'] = real_df['title'] + \" \" + real_df['text']\n",
    "    \n",
    "    # step 5: combine datasets\n",
    "    combined_df = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "    \n",
    "    # step 6: shuffle data\n",
    "    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # step 7: split into train, validation, and test sets\n",
    "    test_size = int(len(combined_df) * test_split)\n",
    "    valid_size = int(len(combined_df) * valid_split)\n",
    "    \n",
    "    test_df = combined_df[:test_size]\n",
    "    valid_df = combined_df[test_size:test_size+valid_size]\n",
    "    train_df = combined_df[test_size+valid_size:]\n",
    "    \n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29948d-2fb6-46a3-9cb2-332f78103654",
   "metadata": {},
   "source": [
    "# Dataset Combination Module\n",
    "\n",
    "The following codeblock handles the integration of both LIAR and ISOT datasets into a unified training pipeline:\n",
    "\n",
    "1. Dataset Loading - Calls the specialized loading functions for both LIAR and ISOT datasets to obtain preprocessed dataframes.\n",
    "2. Data Integration - Concatenates the corresponding splits (train/validation/test) from each dataset while preserving source identification.\n",
    "3. Training Randomization - Shuffles the training data to ensure model convergence isn't affected by dataset order or source grouping.\n",
    "4. Statistics Reporting - Provides detailed counts of samples from each source within each split, offering transparency about dataset composition.\n",
    "\n",
    "This unified approach enables the model to learn from both political statements (LIAR) and full news articles (ISOT) simultaneously, potentially improving generalization across different types of misinformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4498f457-c5e9-4baa-a40c-7be48aed0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load, preprocess and combine both datasets\n",
    "# arguments:\n",
    "# liar_paths - tuple of (train_path, valid_path, test_path) for LIAR dataset\n",
    "# isot_paths - tuple of (fake_path, real_path) for ISOT dataset\n",
    "# return - tuple of (train_df, valid_df, test_df) with combined data\n",
    "def combine_datasets(liar_paths, isot_paths):\n",
    "    # step 1: load datasets\n",
    "    liar_train, liar_valid, liar_test = load_liar_dataset(*liar_paths)\n",
    "    isot_train, isot_valid, isot_test = load_isot_dataset(*isot_paths)\n",
    "    \n",
    "    # step 2: combine datasets\n",
    "    train_df = pd.concat([liar_train, isot_train], ignore_index=True)\n",
    "    valid_df = pd.concat([liar_valid, isot_valid], ignore_index=True)\n",
    "    test_df = pd.concat([liar_test, isot_test], ignore_index=True)\n",
    "    \n",
    "    # step 3: shuffle training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # step 4: print dataset statistics\n",
    "    print(\"Dataset statistics:\")\n",
    "    print(f\"  Train set: {len(train_df)} samples\")\n",
    "    print(f\"    LIAR: {len(liar_train)} samples\")\n",
    "    print(f\"    ISOT: {len(isot_train)} samples\")\n",
    "    print(f\"  Validation set: {len(valid_df)} samples\")\n",
    "    print(f\"    LIAR: {len(liar_valid)} samples\")\n",
    "    print(f\"    ISOT: {len(isot_valid)} samples\")\n",
    "    print(f\"  Test set: {len(test_df)} samples\")\n",
    "    print(f\"    LIAR: {len(liar_test)} samples\")\n",
    "    print(f\"    ISOT: {len(isot_test)} samples\")\n",
    "    \n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836bb892-630a-49a7-9027-529f1f0e660c",
   "metadata": {},
   "source": [
    "# Custom Dataset with Source Tracking Capability\n",
    "\n",
    "The following codeblock implements a PyTorch Dataset class specifically designed for fake news classification with multiple data sources:\n",
    "\n",
    "1. Source-Aware Construction - Stores not only text and labels but also tracks the origin dataset ('liar' or 'isot') of each sample for later evaluation.\n",
    "2. BERT-Compatible Tokenization - Handles text encoding with transformers tokenizer, managing padding, truncation, and tensor conversion automatically.\n",
    "3. PyTorch Integration - Implements standard Dataset methods (len, getitem) for seamless integration with PyTorch DataLoader.\n",
    "4. Source Retrieval - Provides a dedicated method (get_sources) to extract source information during evaluation, enabling dataset-specific performance analysis.\n",
    "\n",
    "This custom dataset enables the pipeline to maintain dataset provenance throughout training and evaluation, allowing for detailed performance analysis on each source individually - crucial for identifying where the model excels or struggles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417c9b77-3470-45dd-9312-01d40bfda013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class that supports source tracking for dataset-aware evaluation\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        # step 1: store dataframe and extract necessary columns\n",
    "        self.df = df\n",
    "        self.texts = df['statement'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.sources = df['source'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # step 1: get text and label for the index\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # step 2: tokenize the text\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # step 3: return the encodings and label\n",
    "        return {\n",
    "            'input_ids': encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    # Method to get sources for dataset-aware evaluation\n",
    "    def get_sources(self):\n",
    "        return self.sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4a37c-758a-4b77-b8a3-bbcd49fae286",
   "metadata": {},
   "source": [
    "# Dataset Balancing: Weighted Sampler\n",
    "\n",
    "The following codeblock implements a weighted sampling strategy to ensure balanced representation of multiple data sources:\n",
    "\n",
    "1. Source Frequency Analysis - Calculates the number of samples from each source (LIAR and ISOT) in the training data.\n",
    "2. Inverse Frequency Weighting - Assigns weights to samples inversely proportional to their source's frequency, giving higher weight to samples from underrepresented sources.\n",
    "3. Balanced Sampling Implementation - Creates a PyTorch WeightedRandomSampler that uses these weights to sample with equal probability from each source dataset.\n",
    "4. Representative Training - Ensures that during each training epoch, the model sees approximately equal numbers of samples from each source, preventing bias toward the larger dataset.\n",
    "\n",
    "This balanced sampling approach is crucial for preventing the model from simply optimizing for the larger dataset (ISOT) while neglecting performance on the more challenging dataset (LIAR), leading to better generalization across diverse fake news contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72897aa7-0044-43b6-842a-94c496c554d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sampler to balance dataset influence during training\n",
    "# arguments:\n",
    "# train_df - training dataframe with 'source' column\n",
    "# return - PyTorch sampler that balances dataset representation\n",
    "def create_balanced_sampler(train_df):\n",
    "    # step 1: calculate weights for each sample based on source\n",
    "    dataset_counts = train_df['source'].value_counts()\n",
    "    total_samples = len(train_df)\n",
    "    \n",
    "    # calculate weights (inverse of dataset frequency)\n",
    "    weights = []\n",
    "    for source in train_df['source']:\n",
    "        source_count = dataset_counts[source]\n",
    "        # weight = total_samples / (num_datasets * source_count)\n",
    "        weight = total_samples / (2 * source_count)  # 2 datasets: LIAR and ISOT\n",
    "        weights.append(weight)\n",
    "    \n",
    "    # step 2: create weighted sampler\n",
    "    weights = torch.FloatTensor(weights)\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(\n",
    "        weights=weights,\n",
    "        num_samples=len(weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4fe8b-ab36-4bee-96d9-09ed96eb032a",
   "metadata": {},
   "source": [
    "# Dataset Balancing: Class Weights\n",
    "\n",
    "The following codeblock implements a class weighting mechanism to address label imbalance during model training:\n",
    "\n",
    "1. Class Distribution Analysis - Counts the frequency of each label (fake vs. real) in the training dataset.\n",
    "2. Inverse Frequency Weighting - Calculates weights inversely proportional to class frequency, giving higher importance to underrepresented classes.\n",
    "3. Class Weight Normalization - Normalizes weights by the number of classes and total samples to maintain balanced training signals.\n",
    "4. Loss Function Integration - Returns class weights as a PyTorch tensor ready for integration with weighted loss functions.\n",
    "\n",
    "This class weighting approach addresses a different dimension of balance than the previous sampler - while the sampler balanced between data sources (LIAR vs. ISOT), this function balances between class labels (fake vs. real) within the combined dataset. Together, these mechanisms ensure the model learns effectively despite imbalances in both dataset size and class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88aa3a3-5f8d-402b-a6b0-15011b9c7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate class weights for loss function to handle class imbalance\n",
    "# arguments:\n",
    "# train_df - training dataframe with 'label' column\n",
    "# return - class weights tensor for balanced loss calculation\n",
    "def calculate_class_weights(train_df):\n",
    "    # step 1: count classes\n",
    "    class_counts = train_df['label'].value_counts().to_dict()\n",
    "    total_samples = len(train_df)\n",
    "    \n",
    "    # step 2: calculate weights (inverse of class frequency)\n",
    "    num_classes = len(class_counts)\n",
    "    weights = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        if class_idx in class_counts:\n",
    "            weight = total_samples / (num_classes * class_counts[class_idx])\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        weights.append(weight)\n",
    "    \n",
    "    # step 3: convert to tensor\n",
    "    class_weights = torch.FloatTensor(weights)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f74e2-363e-4a7e-b6b3-934c87bde77d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics Computation\n",
    "\n",
    "The following codeblock implements a multi-metric evaluation function for assessing fake news classification performance:\n",
    "\n",
    "1. Prediction Processing - Converts raw model outputs (logits) into class predictions by identifying the highest probability class.\n",
    "2. Accuracy Calculation - Measures the overall percentage of correctly classified samples, providing a general performance indicator.\n",
    "3. Precision and Recall Assessment - Evaluates the model's ability to avoid false positives (precision) and catch all instances of fake news (recall).\n",
    "4. F1 Score Computation - Calculates the harmonic mean of precision and recall, offering a balanced metric for classification performance.\n",
    "5. ROC-AUC Evaluation - Assesses the model's ability to distinguish between classes across different classification thresholds, with a safeguard for single-class edge cases.\n",
    "\n",
    "This comprehensive evaluation approach provides multiple perspectives on model performance, allowing for nuanced assessment beyond simple accuracy. These metrics are particularly important in fake news detection where the costs of false positives and false negatives may differ significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b08df448-5216-403d-835b-69a843ecfb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for model evaluation\n",
    "# arguments:\n",
    "# eval_pred - tuple of (predictions, labels)\n",
    "# return - dictionary with evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'precision': precision_score(labels, predictions, zero_division=0),\n",
    "        'recall': recall_score(labels, predictions),\n",
    "        'f1': f1_score(labels, predictions),\n",
    "        'roc_auc': roc_auc_score(labels, predictions) if len(np.unique(labels)) > 1 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066f222-25fe-4cad-a073-dfe710129cfe",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Bayesian optimisation\n",
    "\n",
    "The following codeblock implements an advanced hyperparameter tuning approach using Bayesian optimization through Optuna:\n",
    "\n",
    "1. Parameter Space Exploration - Rather than testing each parameter individually, this approach models the entire parameter space and strategically samples promising combinations based on previous results.\n",
    "2. Efficient Trial Scheduling - Uses Tree-structured Parzen Estimator (TPE) to intelligently focus computational resources on the most promising parameter regions.\n",
    "3. Trial Persistence - Implements a robust checkpointing mechanism that:\n",
    "    - Saves model state after each trial\n",
    "    - Can resume interrupted trials exactly where they left off\n",
    "    - Maintains a database of all trial results for analysis\n",
    "4. Automatic Pruning - Implements early termination of unpromising trials using MedianPruner to save computational resources.\n",
    "5. Comprehensive Analysis - Provides detailed insights including:\n",
    "    - Parameter importance analysis\n",
    "    - Ranking of top-performing configurations\n",
    "    - Performance visualization across the parameter space\n",
    "   \n",
    "This Bayesian approach is significantly more efficient than the previously-implemented grid search, identifying better hyperparameter combinations with fewer trials by learning from previous results. The checkpointing system also ensures resilience against interruptions, making the tuning process more practical for resource-intensive transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25218f84-5854-4802-a82e-214854f19d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform hyperparameter tuning using Bayesian optimization\n",
    "# arguments:\n",
    "# model_name - pretrained model name to use\n",
    "# train_dataset - dataset for model training\n",
    "# valid_dataset - dataset for validation during tuning\n",
    "# train_sampler - sampler for balanced data selection (optional)\n",
    "# n_trials - number of hyperparameter combinations to try (default: 20)\n",
    "#\n",
    "# returns dictionary with best hyperparameter combination\n",
    "def tune_hyperparameters(model_name, train_dataset, valid_dataset, train_sampler, n_trials=20):\n",
    "    # step 1: prepare storage directory\n",
    "    base_dir = \"./hp_tuning_optuna\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # step 2: define objective function for optimization\n",
    "    def objective(trial):\n",
    "        # step 2.1: sample hyperparameter values\n",
    "        lr = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.2, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "        epochs = trial.suggest_int(\"epochs\", 2, 3)\n",
    "        gradient_accumulation_steps = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4]) # new (v2.5 step2)\n",
    "        \n",
    "        # step 2.2: create directory for this trial's outputs\n",
    "        trial_dir = f\"{base_dir}/trial_{trial.number}\"\n",
    "        os.makedirs(trial_dir, exist_ok=True)\n",
    "        \n",
    "        # step 2.3: check for existing checkpoint\n",
    "        checkpoint_path = f\"{trial_dir}/checkpoint.pt\"\n",
    "        start_epoch = 0  # default starting point\n",
    "        \n",
    "        # step 2.4: configure training parameters\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=trial_dir,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            push_to_hub=False,\n",
    "            report_to=\"none\",\n",
    "            logging_steps=500,\n",
    "            disable_tqdm=False,\n",
    "            save_total_limit=1,  # keep only best checkpoint\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps # new (v2.5 step2): gradient accumulation\n",
    "        )\n",
    "        \n",
    "        # step 2.5: initialize model and trainer\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=2\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "        # step 2.6: apply balanced sampling if provided\n",
    "        original_get_train_dataloader = None\n",
    "        if train_sampler is not None:\n",
    "            # create balanced dataloader\n",
    "            train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                sampler=train_sampler\n",
    "            )\n",
    "            # store original method for later restoration\n",
    "            original_get_train_dataloader = trainer.get_train_dataloader\n",
    "            # override with our balanced dataloader\n",
    "            trainer.get_train_dataloader = lambda: train_dataloader\n",
    "        \n",
    "        # step 2.7: attempt to resume from checkpoint if available\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"Resuming from checkpoint for trial {trial.number}\")\n",
    "            checkpoint_state = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint_state['model_state_dict'])\n",
    "            start_epoch = checkpoint_state['epoch']\n",
    "            \n",
    "            # if already completed, just return saved result\n",
    "            if start_epoch >= epochs:\n",
    "                return checkpoint_state['f1_score']\n",
    "        \n",
    "        # step 2.8: train model if not already completed\n",
    "        if start_epoch < epochs:\n",
    "            try:\n",
    "                # perform training\n",
    "                trainer.train()\n",
    "                \n",
    "                # compute performance metrics\n",
    "                eval_result = trainer.evaluate()\n",
    "                f1_score = eval_result[\"eval_f1\"]\n",
    "                \n",
    "                # save checkpoint for possible resumption\n",
    "                torch.save({\n",
    "                    'epoch': epochs,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'f1_score': f1_score\n",
    "                }, checkpoint_path)\n",
    "                \n",
    "                # report result to Optuna\n",
    "                trial.report(f1_score, epochs - 1)\n",
    "                \n",
    "                # restore original dataloader if modified\n",
    "                if original_get_train_dataloader is not None:\n",
    "                    trainer.get_train_dataloader = original_get_train_dataloader\n",
    "                \n",
    "                print(f\"  Trial {trial.number} - F1 Score: {f1_score:.4f}\")\n",
    "                return f1_score\n",
    "                \n",
    "            except Exception as e:\n",
    "                # handle training failures by saving state\n",
    "                if start_epoch > 0:\n",
    "                    torch.save({\n",
    "                        'epoch': start_epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'f1_score': 0  # default for failed runs\n",
    "                    }, checkpoint_path)\n",
    "                print(f\"Training failed: {e}\")\n",
    "                return 0\n",
    "    \n",
    "    # step 3: create and configure the Optuna study\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",  # maximize F1 score\n",
    "        sampler=TPESampler(seed=42),  # use Tree-structured Parzen Estimator\n",
    "        pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=5),  # prune unpromising trials\n",
    "        study_name=\"fake_news_detection\",\n",
    "        storage=f\"sqlite:///{base_dir}/optuna_study.db\",  # persistent storage\n",
    "        load_if_exists=True  # resume existing study if available\n",
    "    )\n",
    "    \n",
    "    # step 4: run optimization process\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # step 5: extract and display results\n",
    "    best_params = study.best_params\n",
    "    best_f1 = study.best_value\n",
    "    \n",
    "    # step 5.1: print summary information\n",
    "    print(\"\\nOptuna hyperparameter tuning complete!\")\n",
    "    print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # step 5.2: show parameter importance if possible\n",
    "    try:\n",
    "        importance = optuna.importance.get_param_importances(study)\n",
    "        print(\"\\nHyperparameter importance:\")\n",
    "        for param, score in importance.items():\n",
    "            print(f\"  {param}: {score:.4f}\")\n",
    "    except:\n",
    "        print(\"Could not calculate hyperparameter importance (requires at least 2 completed trials)\")\n",
    "    \n",
    "    # step 5.3: show top performing configurations\n",
    "    print(\"\\nTop 5 trials:\")\n",
    "    sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value is not None else -1, reverse=True)\n",
    "    for i, trial in enumerate(sorted_trials[:5]):\n",
    "        if trial.value is not None:\n",
    "            print(f\"Rank {i+1}: F1={trial.value:.4f}, Params={trial.params}\")\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcbf0b-bd89-44d7-a702-7494da91679f",
   "metadata": {},
   "source": [
    "# Source-Aware Model Evaluation Framework\n",
    "\n",
    "The following codeblock implements a comprehensive evaluation system that distinguishes performance across different data sources:\n",
    "\n",
    "1. Holistic Assessment - Computes standard metrics (accuracy, precision, recall, F1, ROC-AUC) across the entire test set for baseline performance.\n",
    "2. Dataset-Specific Analysis - Segments evaluation results by source (LIAR vs. ISOT), revealing how the model performs on different types of fake news content.\n",
    "3. Statistical Visualization - Generates confusion matrices both for the overall dataset and for each source individually, providing visual insight into classification patterns.\n",
    "4. Performance Reporting - Formats results into clear, tabular displays that highlight the model's strengths and weaknesses across datasets.\n",
    "5. Error Distribution Analysis - Enables identification of which dataset contributes more significantly to model errors, guiding future improvement efforts.\n",
    "\n",
    "This sophisticated evaluation approach goes beyond simple accuracy metrics to provide crucial insights into model behavior across diverse fake news contexts - revealing whether performance is consistent or if the model excels on certa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19a21ce1-3629-4b04-a8c2-8a76bfa418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate model with dataset awareness\n",
    "# arguments:\n",
    "# trainer - Trainer instance\n",
    "# test_dataset - dataset to evaluate on\n",
    "# return - dictionary with evaluation metrics\n",
    "def evaluate_dataset_aware(trainer, test_dataset):\n",
    "    # step 1: get overall metrics using trainer\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    \n",
    "    # step 2: get dataset-specific metrics\n",
    "    # get predictions\n",
    "    test_predictions = trainer.predict(test_dataset)\n",
    "    predictions = np.argmax(test_predictions.predictions, axis=1)\n",
    "    true_labels = test_predictions.label_ids\n",
    "    sources = test_dataset.get_sources()\n",
    "    \n",
    "    # step 3: convert results to a more readable format\n",
    "    readable_results = {}\n",
    "    for key, value in test_results.items():\n",
    "        # Extract the actual metric name from keys like 'eval_accuracy'\n",
    "        if key.startswith('eval_'):\n",
    "            metric_name = key[5:]  # Remove 'eval_' prefix\n",
    "            readable_results[metric_name] = round(value, 4)  # Round to 4 decimal places\n",
    "        else:\n",
    "            readable_results[key] = value\n",
    "    \n",
    "    # step 4: calculate dataset-specific metrics\n",
    "    dataset_metrics = {'overall': readable_results}\n",
    "    \n",
    "    for source in set(sources):\n",
    "        # Get indices for this source\n",
    "        source_indices = [i for i, s in enumerate(sources) if s == source]\n",
    "        source_preds = [predictions[i] for i in source_indices]\n",
    "        source_labels = [true_labels[i] for i in source_indices]\n",
    "        \n",
    "        # Calculate metrics for this source\n",
    "        if len(source_indices) > 0 and len(set(source_labels)) > 1:\n",
    "            source_metrics = {\n",
    "                'accuracy': round(accuracy_score(source_labels, source_preds), 4),\n",
    "                'precision': round(precision_score(source_labels, source_preds, zero_division=0), 4),\n",
    "                'recall': round(recall_score(source_labels, source_preds), 4),\n",
    "                'f1': round(f1_score(source_labels, source_preds), 4),\n",
    "                'roc_auc': round(roc_auc_score(source_labels, source_preds), 4) if len(set(source_labels)) > 1 else 0\n",
    "            }\n",
    "            dataset_metrics[source] = source_metrics\n",
    "    \n",
    "    # step 5: display overall metrics table\n",
    "    overall_metrics = pd.DataFrame({\n",
    "        'Metric': list(readable_results.keys()),\n",
    "        'Value': list(readable_results.values())\n",
    "    })\n",
    "    print(\"\\nOverall Performance Metrics:\")\n",
    "    print(overall_metrics.set_index('Metric').transpose())\n",
    "    \n",
    "    # step 6: display source-specific metrics\n",
    "    for source in dataset_metrics.keys():\n",
    "        if source != 'overall':\n",
    "            source_df = pd.DataFrame({\n",
    "                'Metric': list(dataset_metrics[source].keys()),\n",
    "                'Value': list(dataset_metrics[source].values())\n",
    "            })\n",
    "            print(f\"\\n{source.upper()} Dataset Performance Metrics:\")\n",
    "            print(source_df.set_index('Metric').transpose())\n",
    "    \n",
    "    # step 7: create overall confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fake\", \"Real\"]).plot(cmap=\"Blues\")\n",
    "    plt.title(\"Overall Fake News Detection Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # step 8: create source-specific confusion matrices\n",
    "    for source in set(sources):\n",
    "        source_indices = [i for i, s in enumerate(sources) if s == source]\n",
    "        if len(source_indices) > 0:\n",
    "            source_preds = [predictions[i] for i in source_indices]\n",
    "            source_labels = [true_labels[i] for i in source_indices]\n",
    "            \n",
    "            cm = confusion_matrix(source_labels, source_preds)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fake\", \"Real\"]).plot(cmap=\"Blues\")\n",
    "            plt.title(f\"{source.upper()} Dataset Fake News Detection Confusion Matrix\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return dataset_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d7214-ab93-45fd-ac7f-daff73936a45",
   "metadata": {},
   "source": [
    "# Unified Fake News Detection Pipeline\n",
    "\n",
    "The following codeblock implements the complete end-to-end pipeline for fake news detection with dataset balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e81f859-2874-43e5-b7be-861f980cbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to run the pipeline with dataset balancing and hyperparameter tuning\n",
    "def run_balanced_fake_news_pipeline():\n",
    "    # step 1: define paths\n",
    "    liar_paths = (\n",
    "        \"data/liar_dataset/train.tsv\",  # LIAR train path\n",
    "        \"data/liar_dataset/valid.tsv\",  # LIAR validation path\n",
    "        \"data/liar_dataset/test.tsv\"    # LIAR test path\n",
    "    )\n",
    "    \n",
    "    isot_paths = (\n",
    "        \"data/isot_dataset/Fake.csv\",   # ISOT fake news path\n",
    "        \"data/isot_dataset/True.csv\"    # ISOT real news path\n",
    "    )\n",
    "    \n",
    "    # step 2: load and combine datasets\n",
    "    train_df, valid_df, test_df = combine_datasets(liar_paths, isot_paths)\n",
    "\n",
    "    def apply_preprocessing(df, text_column):\n",
    "        print(f\"Applying minimal preprocessing to {len(df)} texts...\")\n",
    "        df[text_column] = df[text_column].apply(preprocess_text)\n",
    "        return df\n",
    "\n",
    "    # apply preprocessing to dataframes\n",
    "    train_df = apply_preprocessing(train_df, text_column='statement')\n",
    "    valid_df = apply_preprocessing(valid_df, text_column='statement')\n",
    "    test_df = apply_preprocessing(test_df, text_column='statement')\n",
    "    \n",
    "    # step 3: initialize tokenizer\n",
    "    model_name = \"google/mobilebert-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # step 4: create datasets\n",
    "    train_dataset = FakeNewsDataset(train_df, tokenizer)\n",
    "    valid_dataset = FakeNewsDataset(valid_df, tokenizer)\n",
    "    test_dataset = FakeNewsDataset(test_df, tokenizer)\n",
    "    \n",
    "    # step 5: create balanced sampler for training\n",
    "    print(\"\\nCreating balanced dataset sampler...\")\n",
    "    balanced_sampler = create_balanced_sampler(train_df)\n",
    "    \n",
    "    # step 6: perform hyperparameter tuning with Optuna\n",
    "    best_hparams = tune_hyperparameters(\n",
    "        model_name, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        balanced_sampler,\n",
    "        n_trials=2  # adjust this (trials)\n",
    "    )\n",
    "    \n",
    "    # step 7: train final model with optimal hyperparameters\n",
    "    print(\"\\nTraining final model with optimal hyperparameters...\")\n",
    "    \n",
    "    # configure training with optimal hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./balanced_model\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=best_hparams[\"learning_rate\"],\n",
    "        per_device_train_batch_size=best_hparams[\"batch_size\"],\n",
    "        per_device_eval_batch_size=best_hparams[\"batch_size\"],\n",
    "        num_train_epochs=best_hparams[\"epochs\"],\n",
    "        weight_decay=best_hparams[\"weight_decay\"],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        gradient_accumulation_steps=best_hparams.get(\"gradient_accumulation_steps\", 1) #new (v2.5 step2): gradient accumulation\n",
    "    )\n",
    "    \n",
    "    # initialize model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    # set up early stopping\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=2,\n",
    "        early_stopping_threshold=0.001\n",
    "    )\n",
    "    \n",
    "    # initialize Trainer for final training\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    \n",
    "    # use balanced sampler for final training\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=best_hparams[\"batch_size\"],\n",
    "        sampler=balanced_sampler\n",
    "    )\n",
    "    \n",
    "    # override the get_train_dataloader method to use our balanced loader\n",
    "    original_get_train_dataloader = trainer.get_train_dataloader\n",
    "    trainer.get_train_dataloader = lambda: train_dataloader\n",
    "    \n",
    "    # train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # restore original dataloader method\n",
    "    trainer.get_train_dataloader = original_get_train_dataloader\n",
    "    \n",
    "    # step 8: evaluate with dataset awareness\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    dataset_metrics = evaluate_dataset_aware(trainer, test_dataset)\n",
    "    \n",
    "    # step 9: save model\n",
    "    model_path = \"balanced_fake_news_model_final\"\n",
    "    trainer.save_model(model_path)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    print(f\"\\nModel and tokenizer saved to {model_path}\")\n",
    "    \n",
    "    return trainer, dataset_metrics, best_hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a66dc-e731-41eb-99ca-31bd894699bb",
   "metadata": {},
   "source": [
    "# Model Prediction and LIME Explanation\n",
    "\n",
    "The following code block combines transformer-based classification with explainable AI techniques to implement the functionality to analyse user-inputted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1b128b8-9140-4681-b1ca-6cbc8bbd298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to classify news text and provide explanations of model decisions\n",
    "# arguments:\n",
    "# news_text - input text to classify (string)\n",
    "# model_path - path to the trained model directory (default: 'balanced_fake_news_model_final')\n",
    "# verbose - boolean to display detailed processing information (default: False)\n",
    "# confidence_threshold - minimum confidence required for classification (default: 0.0)\n",
    "# feature_count - number of text features to include in explanation (default: 10)\n",
    "# generate_explanation - boolean to generate LIME explanations (default: True)\n",
    "#\n",
    "# returns tuple of (classification_result, confidence_score, probability_dict, explanation_object)\n",
    "def analyze_news_text(news_text, model_path='balanced_fake_news_model_final', verbose=False, \n",
    "                      confidence_threshold=0.0, feature_count=10, generate_explanation=True):\n",
    "    # step 1: configure execution environment\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if verbose:\n",
    "        print(f\"Using device: {device}\")\n",
    "    \n",
    "    # step 2: load model components\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(\"Loading model and tokenizer...\")\n",
    "        classification_model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        classification_model.eval()  # set model to evaluation mode\n",
    "        if verbose:\n",
    "            print(\"Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, 0.0, {}, None\n",
    "    \n",
    "    # step 3: apply text preprocessing\n",
    "    start_time = time.time()\n",
    "    processed_text = preprocess_text(news_text)\n",
    "    preprocess_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Preprocessed text: {processed_text[:100]}...\" if len(processed_text) > 100 else processed_text)\n",
    "        print(f\"Preprocessing time: {preprocess_time:.4f} seconds\")\n",
    "    \n",
    "    # step 4: tokenize input text\n",
    "    start_time = time.time()\n",
    "    encoded_input = tokenizer(\n",
    "        processed_text,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    tokenize_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Tokenization time: {tokenize_time:.4f} seconds\")\n",
    "    \n",
    "    # step 5: perform model inference\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        model_output = classification_model(**encoded_input)\n",
    "        class_probabilities = torch.nn.functional.softmax(model_output.logits, dim=1)\n",
    "        fake_probability = class_probabilities[0][0].item()\n",
    "        real_probability = class_probabilities[0][1].item()\n",
    "        predicted_class = 0 if fake_probability > real_probability else 1\n",
    "        confidence_score = fake_probability if predicted_class == 0 else real_probability\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "        print(f\"Probabilities: FAKE={fake_probability*100:.2f}%, REAL={real_probability*100:.2f}%\")\n",
    "    \n",
    "    # step 6: prepare classification result\n",
    "    classification_result = \"FAKE\" if predicted_class == 0 else \"REAL\"\n",
    "    \n",
    "    if confidence_score < confidence_threshold:\n",
    "        if verbose:\n",
    "            print(f\"Classification: UNCERTAIN (confidence below threshold)\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"Classification: {classification_result}\")\n",
    "            print(f\"Confidence: {confidence_score*100:.2f}%\")\n",
    "    \n",
    "    explanation_object = None\n",
    "    \n",
    "    # step 7: generate model explanation if requested\n",
    "    if generate_explanation:\n",
    "        if verbose:\n",
    "            print(\"\\nGenerating explanation...\")\n",
    "            \n",
    "        # define model wrapper for LIME compatibility\n",
    "        class TransformerModelWrapper:\n",
    "            def __init__(self, model, tokenizer, max_length=128, device='cpu'):\n",
    "                self.model = model\n",
    "                self.tokenizer = tokenizer\n",
    "                self.max_length = max_length\n",
    "                self.device = device\n",
    "\n",
    "            def predict_proba(self, text_samples):\n",
    "                # encode text samples for model input\n",
    "                encodings = self.tokenizer(\n",
    "                    text_samples,\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=self.max_length,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                input_ids = encodings['input_ids'].to(self.device)\n",
    "                attention_mask = encodings['attention_mask'].to(self.device)\n",
    "\n",
    "                # generate predictions with no gradient tracking\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "                    logits = outputs.logits\n",
    "\n",
    "                # convert logits to probability distribution\n",
    "                probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "                return probabilities\n",
    "        \n",
    "        # initialize and run explainer\n",
    "        start_time = time.time()\n",
    "        explainer = LimeTextExplainer(class_names=[\"Fake\", \"Real\"])\n",
    "        model_wrapper = TransformerModelWrapper(classification_model, tokenizer, device=device)\n",
    "        \n",
    "        # generate explanation for prediction\n",
    "        try:\n",
    "            explanation_object = explainer.explain_instance(\n",
    "                processed_text, \n",
    "                model_wrapper.predict_proba, \n",
    "                num_features=feature_count,\n",
    "                top_labels=1  # focus on predicted class\n",
    "            )\n",
    "            \n",
    "            explain_time = time.time() - start_time\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Explanation generation time: {explain_time:.4f} seconds\")\n",
    "                print(\"\\nTop words influencing classification:\")\n",
    "                \n",
    "            # extract and display explanation\n",
    "            if verbose:\n",
    "                print(f\"\\nWords influencing {'FAKE' if predicted_class == 0 else 'REAL'} classification:\")\n",
    "                \n",
    "                # extract feature weights for predicted class\n",
    "                feature_weights = explanation_object.as_list(label=predicted_class)\n",
    "                \n",
    "                # display features and their impact on classification\n",
    "                for feature, weight in feature_weights:\n",
    "                    impact_symbol = '+' if weight > 0 else '-'\n",
    "                    print(f\"  {impact_symbol} {feature}: {weight:.4f}\")\n",
    "                \n",
    "                # visualize explanation with matplotlib\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                explanation_object.as_pyplot_figure(label=predicted_class)\n",
    "                plt.title(f\"Words influencing {'FAKE' if predicted_class == 0 else 'REAL'} classification\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating explanation: {e}\")\n",
    "    \n",
    "    # create probability dictionary for return value\n",
    "    probability_dict = {\"fake_probability\": fake_probability, \"real_probability\": real_probability}\n",
    "    \n",
    "    return classification_result, confidence_score, probability_dict, explanation_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ebfc6-65db-446c-8320-7181561118b6",
   "metadata": {},
   "source": [
    "# Text (Command-Line) Interface \n",
    "\n",
    "The following codeblock implements a user-friendly command-line interface for the fake news detection system. \n",
    "It provides a continuous interactive loop where users can input news text and receive immediate classification results with explanations.\n",
    "\n",
    "The interface handles various operational scenarios, including:\n",
    "- Processing valid news text with the underlying model\n",
    "- Validating empty inputs to prevent errors\n",
    "- Providing clean exit paths through 'exit' command or keyboard interrupts\n",
    "- Gracefully managing unexpected exceptions during analysis\n",
    "\n",
    "This component serves as the primary user interaction layer for the text-based application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2644bef8-7f4d-4c2f-afe5-53c645e9f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to provide an interactive text interface for news classification\n",
    "# arguments:\n",
    "# model_path - path to the trained model directory (default: 'balanced_fake_news_model_final')\n",
    "# confidence_threshold - minimum confidence required for classification (default: 0.6)\n",
    "# feature_count - number of text features to include in explanation (default: 10)\n",
    "#\n",
    "# returns None\n",
    "def run_interactive_text_interface(model_path='balanced_fake_news_model_final', \n",
    "                                   confidence_threshold=0.6, feature_count=10):\n",
    "    # step 1: initialize interface\n",
    "    print(\"=== Fake News Detection System ===\")\n",
    "    print(\"Enter news text to classify (type 'exit' to quit):\")\n",
    "    \n",
    "    # step 2: process user inputs in continuous loop\n",
    "    while True:\n",
    "        try:\n",
    "            # step 2.1: capture user input\n",
    "            input_text = input(\"\\nInput: \")\n",
    "            \n",
    "            # step 2.2: handle exit condition\n",
    "            if input_text.lower() == 'exit':\n",
    "                print(\"Exiting system. Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            # step 2.3: validate input\n",
    "            if input_text.strip() == \"\":\n",
    "                print(\"Please enter some text to classify.\")\n",
    "                continue\n",
    "            \n",
    "            # step 2.4: perform analysis with integrated explanation\n",
    "            classification_result, confidence_score, probability_dict, explanation_object = analyze_news_text(\n",
    "                news_text=input_text, \n",
    "                model_path=model_path,\n",
    "                verbose=True, \n",
    "                confidence_threshold=confidence_threshold, \n",
    "                feature_count=feature_count,\n",
    "                generate_explanation=True\n",
    "            )\n",
    "            \n",
    "            # Note: Results are displayed by the analyze_news_text function\n",
    "            \n",
    "        # step 3: handle execution interruptions\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nOperation interrupted by user. Exiting...\")\n",
    "            break\n",
    "            \n",
    "        # step 4: handle unexpected errors gracefully\n",
    "        except Exception as e:\n",
    "            print(f\"Error during text analysis: {e}\")\n",
    "            print(\"Please try again with different input.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b72a5129-1d7f-4133-a6b5-4343e6d63f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pipeline \n",
    "# uncomment both lines of code below to run the full pipeline:\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_balanced_fake_news_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c578eace-fd1f-438b-8dc6-36f45c4618c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fake News Detection System ===\n",
      "Enter news text to classify (type 'exit' to quit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Input:  Water is red.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model and tokenizer...\n",
      "Model loaded successfully!\n",
      "Water is red.\n",
      "Preprocessing time: 0.0000 seconds\n",
      "Tokenization time: 0.0020 seconds\n",
      "Inference time: 0.2556 seconds\n",
      "Probabilities: FAKE=84.53%, REAL=15.47%\n",
      "Classification: FAKE\n",
      "Confidence: 84.53%\n",
      "\n",
      "Generating explanation...\n",
      "Explanation generation time: 0.5952 seconds\n",
      "\n",
      "Top words influencing classification:\n",
      "\n",
      "Words influencing FAKE classification:\n",
      "  + red: 0.2738\n",
      "  + is: 0.0715\n",
      "  - Water: -0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for user: run this\n",
    "classify_text_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8a741-59ce-4b4c-aa64-39fcb008787b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
