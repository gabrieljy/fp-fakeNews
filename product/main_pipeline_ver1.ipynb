{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ca4615-4f17-4d4d-8a4c-5f675a559276",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pip install statements\n",
    "\n",
    "# %pip install transformers \n",
    "# %pip install pandas \n",
    "# %pip install numpy \n",
    "# %pip install scikit-learn \n",
    "# %pip install matplotlib \n",
    "# %pip install shap\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "# %pip install tf-keras\n",
    "# %pip install lime\n",
    "# %pip install tokeniser\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7611c874-9b67-40f5-a4f4-36421eb10f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id        label                                          statement  \\\n",
      "0   2635.json        false  Says the Annies List political group supports ...   \n",
      "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
      "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
      "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
      "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
      "\n",
      "                              subject         speaker     speaker_job_title  \\\n",
      "0                            abortion    dwayne-bohac  State representative   \n",
      "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
      "2                      foreign-policy    barack-obama             President   \n",
      "3                         health-care    blog-posting                   NaN   \n",
      "4                        economy,jobs   charlie-crist                   NaN   \n",
      "\n",
      "  state_info party_affiliation  barely_true_counts  false_counts  \\\n",
      "0      Texas        republican                 0.0           1.0   \n",
      "1   Virginia          democrat                 0.0           0.0   \n",
      "2   Illinois          democrat                70.0          71.0   \n",
      "3        NaN              none                 7.0          19.0   \n",
      "4    Florida          democrat                15.0           9.0   \n",
      "\n",
      "   half_true_counts  mostly_true_counts  pants_on_fire_counts  \\\n",
      "0               0.0                 0.0                   0.0   \n",
      "1               1.0                 1.0                   0.0   \n",
      "2             160.0               163.0                   9.0   \n",
      "3               3.0                 5.0                  44.0   \n",
      "4              20.0                19.0                   2.0   \n",
      "\n",
      "               context  \n",
      "0             a mailer  \n",
      "1      a floor speech.  \n",
      "2               Denver  \n",
      "3       a news release  \n",
      "4  an interview on CNN  \n"
     ]
    }
   ],
   "source": [
    "# load dataset to pandas DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load train, test, validation datasets\n",
    "# for the purposes of this demo, we'll be using LIAR dataset :D\n",
    "train_ds = \"liar_dataset/train.tsv\"\n",
    "test_ds = \"liar_dataset/test.tsv\"\n",
    "valid_ds = \"liar_dataset/valid.tsv\"\n",
    "\n",
    "# now, i'll use pandas to read TSV files :D\n",
    "# columns are as according to the README in liar_dataset directory :D\n",
    "\n",
    "columns = [\n",
    "    \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job_title\",\n",
    "    \"state_info\", \"party_affiliation\", \"barely_true_counts\", \"false_counts\",\n",
    "    \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv(train_ds, sep='\\t', names=columns)\n",
    "test_df = pd.read_csv(test_ds, sep='\\t', names=columns)\n",
    "valid_df = pd.read_csv(valid_ds, sep='\\t', names=columns)\n",
    "\n",
    "# print statement to check the dataset has been loaded properly! T^T\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2c18e6-9282-4fbe-b5b1-81c916d65ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  label                                          statement  \\\n",
      "0   2635.json      0  Says the Annies List political group supports ...   \n",
      "1  10540.json      1  When did the decline of coal start? It started...   \n",
      "2    324.json      1  Hillary Clinton agrees with John McCain \"by vo...   \n",
      "3   1123.json      0  Health care reform legislation is likely to ma...   \n",
      "4   9028.json      1  The economic turnaround started at the end of ...   \n",
      "\n",
      "                              subject         speaker     speaker_job_title  \\\n",
      "0                            abortion    dwayne-bohac  State representative   \n",
      "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
      "2                      foreign-policy    barack-obama             President   \n",
      "3                         health-care    blog-posting                   NaN   \n",
      "4                        economy,jobs   charlie-crist                   NaN   \n",
      "\n",
      "  state_info party_affiliation  barely_true_counts  false_counts  \\\n",
      "0      Texas        republican                 0.0           1.0   \n",
      "1   Virginia          democrat                 0.0           0.0   \n",
      "2   Illinois          democrat                70.0          71.0   \n",
      "3        NaN              none                 7.0          19.0   \n",
      "4    Florida          democrat                15.0           9.0   \n",
      "\n",
      "   half_true_counts  mostly_true_counts  pants_on_fire_counts  \\\n",
      "0               0.0                 0.0                   0.0   \n",
      "1               1.0                 1.0                   0.0   \n",
      "2             160.0               163.0                   9.0   \n",
      "3               3.0                 5.0                  44.0   \n",
      "4              20.0                19.0                   2.0   \n",
      "\n",
      "               context  \n",
      "0             a mailer  \n",
      "1      a floor speech.  \n",
      "2               Denver  \n",
      "3       a news release  \n",
      "4  an interview on CNN  \n",
      "           id  label                                          statement  \\\n",
      "0  11972.json      1  Building a wall on the U.S.-Mexico border will...   \n",
      "1  11685.json      0  Wisconsin is on pace to double the number of l...   \n",
      "2  11096.json      0  Says John McCain has done nothing to help the ...   \n",
      "3   5209.json      1  Suzanne Bonamici supports a plan that will cut...   \n",
      "4   9524.json      0  When asked by a reporter whether hes at the ce...   \n",
      "\n",
      "                                             subject  \\\n",
      "0                                        immigration   \n",
      "1                                               jobs   \n",
      "2                    military,veterans,voting-record   \n",
      "3  medicare,message-machine-2012,campaign-adverti...   \n",
      "4  campaign-finance,legal-issues,campaign-adverti...   \n",
      "\n",
      "                            speaker     speaker_job_title state_info  \\\n",
      "0                        rick-perry              Governor      Texas   \n",
      "1                 katrina-shankland  State representative  Wisconsin   \n",
      "2                      donald-trump       President-Elect   New York   \n",
      "3                     rob-cornilles            consultant     Oregon   \n",
      "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
      "\n",
      "  party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
      "0        republican                  30            30                42   \n",
      "1          democrat                   2             1                 0   \n",
      "2        republican                  63           114                51   \n",
      "3        republican                   1             1                 3   \n",
      "4          democrat                   5             7                 2   \n",
      "\n",
      "   mostly_true_counts  pants_on_fire_counts                       context  \n",
      "0                  23                    18               Radio interview  \n",
      "1                   0                     0             a news conference  \n",
      "2                  37                    61  comments on ABC's This Week.  \n",
      "3                   1                     1                  a radio show  \n",
      "4                   2                     7                   a web video  \n",
      "           id  label                                          statement  \\\n",
      "0  12134.json      0  We have less Americans working now than in the...   \n",
      "1    238.json      0  When Obama was sworn into office, he DID NOT u...   \n",
      "2   7891.json      0  Says Having organizations parading as being so...   \n",
      "3   8169.json      1     Says nearly half of Oregons children are poor.   \n",
      "4    929.json      1  On attacks by Republicans that various program...   \n",
      "\n",
      "                            subject          speaker  \\\n",
      "0                      economy,jobs   vicky-hartzler   \n",
      "1  obama-birth-certificate,religion      chain-email   \n",
      "2   campaign-finance,congress,taxes  earl-blumenauer   \n",
      "3                           poverty  jim-francesconi   \n",
      "4                  economy,stimulus     barack-obama   \n",
      "\n",
      "                               speaker_job_title state_info party_affiliation  \\\n",
      "0                            U.S. Representative   Missouri        republican   \n",
      "1                                            NaN        NaN              none   \n",
      "2                            U.S. representative     Oregon          democrat   \n",
      "3  Member of the State Board of Higher Education     Oregon              none   \n",
      "4                                      President   Illinois          democrat   \n",
      "\n",
      "   barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
      "0                   1             0                 1                   0   \n",
      "1                  11            43                 8                   5   \n",
      "2                   0             1                 1                   1   \n",
      "3                   0             1                 1                   1   \n",
      "4                  70            71               160                 163   \n",
      "\n",
      "   pants_on_fire_counts                        context  \n",
      "0                     0   an interview with ABC17 News  \n",
      "1                   105                            NaN  \n",
      "2                     0  a U.S. Ways and Means hearing  \n",
      "3                     0             an opinion article  \n",
      "4                     9        interview with CBS News  \n",
      "Unique labels in training data: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# binarising labels! \n",
    "\n",
    "# since the labels have multiple classes, \n",
    "# for the sake of this feature prototype,\n",
    "# i'll just simplify them to binary true/fake labels :)\n",
    "\n",
    "# map labels to binary classes! :D\n",
    "# 'pants-fire', 'false', 'barely-true' -> fake (0)\n",
    "# others -> real (1)\n",
    "\n",
    "def binarise(df):\n",
    "    # validate expected labels exist before applying transformation!\n",
    "    expected_labels = [\"pants-fire\", \"false\", \"barely-true\", \"half-true\", \"mostly-true\", \"true\"]\n",
    "    unexpected_labels = set(df['label']) - set(expected_labels)\n",
    "    if unexpected_labels:\n",
    "        raise ValueError(f\"Unexpected labels found: {unexpected_labels}\")\n",
    "    df['label'] = df['label'].apply(lambda x: 0 if x in ['pants-fire', 'false', 'barely-true'] else 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = binarise(train_df)\n",
    "test_df = binarise(test_df)\n",
    "valid_df = binarise(valid_df)\n",
    "\n",
    "# print statement to check df structure!\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(valid_df.head())\n",
    "\n",
    "# checking that all labels in dataset are valid\n",
    "print(\"Unique labels in training data:\", train_df['label'].unique())\n",
    "assert set(train_df['label'].unique()) == {0, 1}, \"Labels must be binary (0 or 1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10ef6ef-74d8-4770-8c52-e7b8c9f1ffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token length: 128\n",
      "Sample tokenized input IDs: tensor([  101,  2758,  1996,  8194,  2015,  2862,  2576,  2177,  6753,  2353,\n",
      "         1011, 12241, 20367, 11324,  2015,  2006,  5157,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Sample attention mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Number of tokens per sequence: tensor([19, 32, 24,  ..., 33, 19, 38])\n"
     ]
    }
   ],
   "source": [
    "# tokenise statements\n",
    "# i'll tokenise statements using Hugging Face's tokeniser! \n",
    "\n",
    "# import autotokeniser\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# load tokeniser\n",
    "tokeniser = AutoTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "\n",
    "# tokenise data\n",
    "def tokenise(df, tokeniser, max_length=128):\n",
    "    return tokeniser(\n",
    "        df['statement'].tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_encodings = tokenise(train_df, tokeniser)\n",
    "test_encodings = tokenise(test_df, tokeniser)\n",
    "valid_encodings = tokenise(valid_df, tokeniser)\n",
    "\n",
    "# for debug\n",
    "print(\"Max token length:\", max([len(ids) for ids in train_encodings['input_ids']]))\n",
    "print(\"Sample tokenized input IDs:\", train_encodings['input_ids'][0])\n",
    "print(\"Sample attention mask:\", train_encodings['attention_mask'][0])\n",
    "print(\"Number of tokens per sequence:\", train_encodings['attention_mask'].sum(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b897b22-03a7-4e4e-a29d-9a3cf3849753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='764' max='6400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 764/6400 03:40 < 27:08, 3.46 it/s, Epoch 1.19/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39373.743800</td>\n",
       "      <td>0.652544</td>\n",
       "      <td>0.629283</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>0.763473</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.623620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries for Trainer API\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define a dataset class compatible with the Trainer API\n",
    "class LIARDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.texts = df['statement'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create dataset objects that perform tokenization on the fly\n",
    "train_dataset = LIARDataset(train_df, tokeniser)\n",
    "valid_dataset = LIARDataset(valid_df, tokeniser)\n",
    "test_dataset = LIARDataset(test_df, tokeniser)\n",
    "\n",
    "# Define metrics computation function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'precision': precision_score(labels, predictions, zero_division=0),\n",
    "        'recall': recall_score(labels, predictions),\n",
    "        'f1': f1_score(labels, predictions),\n",
    "        # Only compute ROC-AUC when we have both classes in the batch\n",
    "        'roc_auc': roc_auc_score(labels, predictions) if len(np.unique(labels)) > 1 else 0\n",
    "    }\n",
    "\n",
    "# Load model as before\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/mobilebert-uncased\", num_labels=2)\n",
    "\n",
    "# Configure training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"mobilebert_fake_news\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,  # Start with fewer epochs to prevent overfitting\n",
    "    weight_decay=0.01,   # Add regularization to help with overfitting\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"     # Disable wandb or other reporting to simplify\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model and tokenizer\n",
    "model_path = \"mobilebert_fake_news_final\"\n",
    "trainer.save_model(model_path)\n",
    "tokeniser.save_pretrained(model_path)\n",
    "print(f\"Model and tokenizer saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4585635-f511-4a49-bf4f-5295ec7d07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set using the trainer\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Get test results\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "# Convert results to a more readable format\n",
    "readable_results = {}\n",
    "for key, value in test_results.items():\n",
    "    # Extract the actual metric name from keys like 'eval_accuracy'\n",
    "    if key.startswith('eval_'):\n",
    "        metric_name = key[5:]  # Remove 'eval_' prefix\n",
    "        readable_results[metric_name] = round(value, 4)  # Round to 4 decimal places\n",
    "    else:\n",
    "        readable_results[key] = value\n",
    "\n",
    "# Create a DataFrame for better display\n",
    "# First, prepare data as two columns\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': list(readable_results.keys()),\n",
    "    'Value': list(readable_results.values())\n",
    "})\n",
    "\n",
    "# Display the table with improved formatting\n",
    "print(\"\\n===== FAKE NEWS DETECTION MODEL EVALUATION =====\\n\")\n",
    "display(metrics.set_index('Metric').transpose())\n",
    "\n",
    "# If you prefer a standard print output instead of the DataFrame:\n",
    "print(\"\\nDetailed Performance Metrics:\")\n",
    "for metric, value in readable_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric.capitalize():20} : {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric.capitalize():20} : {value}\")\n",
    "\n",
    "# Get predictions for confusion matrix\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(test_predictions.predictions, axis=1)\n",
    "true_labels = test_predictions.label_ids\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "labels = train_df['label'].unique()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fake\", \"Real\"])\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Fake News Detection Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f06011-054c-4e89-9f3f-f5b9d97e2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define a wrapper for model predictions\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model, tokenizer, max_length=128):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        # Get the device from the model\n",
    "        self.device = next(model.parameters()).device\n",
    "    \n",
    "    def predict_proba(self, texts):\n",
    "        # Tokenize the input texts\n",
    "        encodings = self.tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encodings['input_ids'].to(self.device)\n",
    "        attention_mask = encodings['attention_mask'].to(self.device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "# Initialize the LIME explainer with class names matching your model's output\n",
    "explainer = LimeTextExplainer(class_names=[\"Fake\", \"Real\"])\n",
    "\n",
    "# Wrap model and tokenizer\n",
    "wrapper = ModelWrapper(model, tokeniser)\n",
    "\n",
    "# Select a sample from test data to explain\n",
    "sample_index = 0  # You can change this to explain different examples\n",
    "sample_text = test_df['statement'].iloc[sample_index]\n",
    "sample_label = test_df['label'].iloc[sample_index]\n",
    "\n",
    "# Get the model's prediction for this sample (for logging purposes)\n",
    "prediction = wrapper.predict_proba([sample_text])[0]\n",
    "predicted_label = np.argmax(prediction)\n",
    "predicted_class = \"Real\" if predicted_label == 1 else \"Fake\"\n",
    "\n",
    "# Print basic information\n",
    "print(f\"Original Text: {sample_text}\")\n",
    "print(f\"True Label: {'Real' if sample_label == 1 else 'Fake'}\")\n",
    "print(f\"Predicted Label: {predicted_class} (confidence: {prediction[predicted_label]:.4f})\")\n",
    "\n",
    "# Generate explanation\n",
    "explanation = explainer.explain_instance(\n",
    "    sample_text, \n",
    "    wrapper.predict_proba, \n",
    "    num_features=10,\n",
    "    top_labels=1  # Include both classes\n",
    ")\n",
    "\n",
    "# Display the visualization in the notebook\n",
    "# This will generate the visualization similar to the one in the image\n",
    "plt.figure(figsize=(10, 6))\n",
    "explanation.show_in_notebook(text=True)\n",
    "\n",
    "# If you want to customize the visualization colors, you can add:\n",
    "# explanation.as_pyplot_figure(label=predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea094f3f-b6c4-4862-b7b1-7775a269abad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48d888-54df-4305-9f26-5d911a910918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2cd5e-9a1e-456b-81ab-e1e24d97c415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95131d-e760-4a24-abcf-4ec5dfcad707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042708aa-500c-4e54-8b74-ec63092eebff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05d53f-ee27-4349-b599-53b347781905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d6bb5-9e4f-4bd0-b261-d2632cc84f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139c8a9-261a-4c74-9795-5c228e0a5641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722bdb8-9ea3-4a2a-bd03-b4bfd90fc3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39b262-2272-4fac-b5a2-3b338e05a5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e56ab-1cb9-4b5d-b762-f23a70388525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
