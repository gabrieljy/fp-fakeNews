{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d1442b-b61a-44b7-8db2-ca83228a30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISOT Fake News Detection Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import re\n",
    "import time\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf3f986-e120-438c-8782-d79a67a01af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform minimal text preprocessing for transformer models\n",
    "# arguments:\n",
    "# text - input text to preprocess (string)\n",
    "# max_length - maximum number of words to keep (default: 512)\n",
    "#\n",
    "# returns preprocessed text string\n",
    "def preprocess_text(text, max_length=512):\n",
    "    # step 1: handle edge cases\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # step 2: clean encoding issues\n",
    "    # remove non-ascii characters that could cause problems\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # step 3: normalize text format\n",
    "    # replace multiple whitespace characters with single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # step 4: truncate oversized inputs\n",
    "    # transformer models have context length limits\n",
    "    words = text.split()\n",
    "    if len(words) > max_length:\n",
    "        text = ' '.join(words[:max_length])\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34ce49e-ce24-4819-8b16-ab1ac449ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load and preprocess ISOT dataset\n",
    "# arguments:\n",
    "# isot_paths - tuple of paths to (fake_news_path, true_news_path)\n",
    "# return - tuple of (train_df, valid_df, test_df) with preprocessed data\n",
    "def load_isot_dataset(isot_paths=(\"data/isot_dataset/Fake.csv\", \"data/isot_dataset/True.csv\")):\n",
    "    # step 1: load the raw dataset\n",
    "    fake_path, true_path = isot_paths\n",
    "    print(f\"Loading ISOT dataset from {fake_path} and {true_path}...\")\n",
    "    \n",
    "    # Load fake news\n",
    "    fake_df = pd.read_csv(fake_path)\n",
    "    fake_df['label'] = 0  # 0 for fake\n",
    "    \n",
    "    # Load true news\n",
    "    true_df = pd.read_csv(true_path)\n",
    "    true_df['label'] = 1  # 1 for real\n",
    "    \n",
    "    # step 2: combine datasets\n",
    "    isot_df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "    \n",
    "    # step 3: create statement column (title + text)\n",
    "    isot_df['statement'] = isot_df['title'] + \" \" + isot_df['text'].fillna(\"\")\n",
    "    \n",
    "    # step 4: keep only needed columns\n",
    "    isot_df = isot_df[['statement', 'label']]\n",
    "    \n",
    "    # step 5: apply preprocessing\n",
    "    print(\"Applying text preprocessing...\")\n",
    "    isot_df['statement'] = isot_df['statement'].apply(preprocess_text)\n",
    "\n",
    "    # step 6: do train/valid/test split\n",
    "    train_df, temp_df = train_test_split(isot_df, test_size=0.2, random_state=42)\n",
    "    valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # step 7: print dataset statistics\n",
    "    print(f\"ISOT dataset statistics:\")\n",
    "    print(f\"  Total: {len(isot_df)} samples\")\n",
    "    print(f\"  Train: {len(train_df)} samples\")\n",
    "    print(f\"  Valid: {len(valid_df)} samples\")\n",
    "    print(f\"  Test: {len(test_df)} samples\")\n",
    "    \n",
    "    # step 8: check class balance\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(f\"  Overall: {isot_df['label'].value_counts().to_dict()}\")\n",
    "    print(f\"  Train: {train_df['label'].value_counts().to_dict()}\")\n",
    "    print(f\"  Valid: {valid_df['label'].value_counts().to_dict()}\")\n",
    "    print(f\"  Test: {test_df['label'].value_counts().to_dict()}\")\n",
    "\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4f18fc-2ab2-4168-afb3-edb173a81235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class for ISOT fake news detection\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        # step 1: store dataframe and extract necessary columns\n",
    "        self.df = df\n",
    "        self.texts = df['statement'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # step 1: get text and label for the index\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # step 2: tokenize the text\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # step 3: return the encodings and label\n",
    "        return {\n",
    "            'input_ids': encodings['input_ids'].squeeze(),\n",
    "            'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4d6f35-28ae-48be-b99e-210d537486b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for model evaluation\n",
    "# arguments:\n",
    "# eval_pred - tuple of (predictions, labels)\n",
    "# return - dictionary with evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'precision': precision_score(labels, predictions, zero_division=0),\n",
    "        'recall': recall_score(labels, predictions),\n",
    "        'f1': f1_score(labels, predictions),\n",
    "        'roc_auc': roc_auc_score(labels, predictions) if len(np.unique(labels)) > 1 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c02c5c7-b567-4534-b0fb-6f96efd0f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform hyperparameter tuning using Bayesian optimization\n",
    "# arguments:\n",
    "# model_name - pretrained model name to use\n",
    "# train_dataset - dataset for model training\n",
    "# valid_dataset - dataset for validation during tuning\n",
    "# n_trials - number of hyperparameter combinations to try (default: 20)\n",
    "#\n",
    "# returns dictionary with best hyperparameter combination\n",
    "def tune_hyperparameters(model_name, train_dataset, valid_dataset, n_trials):\n",
    "    # step 1: prepare storage directory\n",
    "    base_dir = \"./isot_hp_tuning_optuna\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # step 2: define objective function for optimization\n",
    "    def objective(trial):\n",
    "        # step 2.1: sample hyperparameter values\n",
    "        lr = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 0.01, 0.2, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "        epochs = trial.suggest_int(\"epochs\", 2, 3)\n",
    "        gradient_accumulation_steps = trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4]) # new (v2.5 step2)\n",
    "        \n",
    "        # step 2.2: create directory for this trial's outputs\n",
    "        trial_dir = f\"{base_dir}/trial_{trial.number}\"\n",
    "        os.makedirs(trial_dir, exist_ok=True)\n",
    "        \n",
    "        # step 2.3: check for existing checkpoint\n",
    "        checkpoint_path = f\"{trial_dir}/checkpoint.pt\"\n",
    "        start_epoch = 0  # default starting point\n",
    "        \n",
    "        # step 2.4: configure training parameters\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=trial_dir,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            push_to_hub=False,\n",
    "            report_to=\"none\",\n",
    "            logging_steps=500,\n",
    "            disable_tqdm=False,\n",
    "            save_total_limit=1,  # keep only best checkpoint\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps\n",
    "        )\n",
    "        \n",
    "        # step 2.5: initialize model and trainer\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=2\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "        # step 2.7: attempt to resume from checkpoint if available\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"Resuming from checkpoint for trial {trial.number}\")\n",
    "            checkpoint_state = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint_state['model_state_dict'])\n",
    "            start_epoch = checkpoint_state['epoch']\n",
    "            \n",
    "            # if already completed, just return saved result\n",
    "            if start_epoch >= epochs:\n",
    "                return checkpoint_state['f1_score']\n",
    "        \n",
    "        # step 2.8: train model if not already completed\n",
    "        if start_epoch < epochs:\n",
    "            try:\n",
    "                # perform training\n",
    "                trainer.train()\n",
    "                \n",
    "                # compute performance metrics\n",
    "                eval_result = trainer.evaluate()\n",
    "                f1_score = eval_result[\"eval_f1\"]\n",
    "                \n",
    "                # save checkpoint for possible resumption\n",
    "                torch.save({\n",
    "                    'epoch': epochs,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'f1_score': f1_score\n",
    "                }, checkpoint_path)\n",
    "                \n",
    "                # report result to Optuna\n",
    "                trial.report(f1_score, epochs - 1)\n",
    "                \n",
    "                print(f\"  Trial {trial.number} - F1 Score: {f1_score:.4f}\")\n",
    "                return f1_score\n",
    "                \n",
    "            except Exception as e:\n",
    "                # handle training failures by saving state\n",
    "                if start_epoch > 0:\n",
    "                    torch.save({\n",
    "                        'epoch': start_epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'f1_score': 0  # default for failed runs\n",
    "                    }, checkpoint_path)\n",
    "                print(f\"Training failed: {e}\")\n",
    "                return 0\n",
    "    \n",
    "    # step 3: create and configure the Optuna study\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",  # maximize F1 score\n",
    "        sampler=TPESampler(seed=42),  # use Tree-structured Parzen Estimator\n",
    "        pruner=MedianPruner(n_startup_trials=1, n_warmup_steps=1),  # prune unpromising trials\n",
    "        study_name=\"isot_fake_news_detection\",\n",
    "        storage=f\"sqlite:///{base_dir}/optuna_study.db\",  # persistent storage\n",
    "        load_if_exists=True  # resume existing study if available\n",
    "    )\n",
    "    \n",
    "    # step 4: run optimization process\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # step 5: extract and display results\n",
    "    best_params = study.best_params\n",
    "    best_f1 = study.best_value\n",
    "    \n",
    "    # step 5.1: print summary information\n",
    "    print(\"\\nOptuna hyperparameter tuning complete!\")\n",
    "    print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # step 5.2: show parameter importance if possible\n",
    "    try:\n",
    "        importance = optuna.importance.get_param_importances(study)\n",
    "        print(\"\\nHyperparameter importance:\")\n",
    "        for param, score in importance.items():\n",
    "            print(f\"  {param}: {score:.4f}\")\n",
    "    except:\n",
    "        print(\"Could not calculate hyperparameter importance (requires at least 2 completed trials)\")\n",
    "    \n",
    "    # step 5.3: show top performing configurations\n",
    "    print(\"\\nTop 5 trials:\")\n",
    "    sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value is not None else -1, reverse=True)\n",
    "    for i, trial in enumerate(sorted_trials[:5]):\n",
    "        if trial.value is not None:\n",
    "            print(f\"Rank {i+1}: F1={trial.value:.4f}, Params={trial.params}\")\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cf2703-b6b8-4b0e-a472-9b8a85b89417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate model performance\n",
    "# arguments:\n",
    "# trainer - Trainer instance\n",
    "# test_dataset - dataset to evaluate on\n",
    "# return - dictionary with evaluation metrics\n",
    "def evaluate_model(trainer, test_dataset):\n",
    "    # step 1: get overall metrics using trainer\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    \n",
    "    # step 2: get predictions for more detailed analysis\n",
    "    test_predictions = trainer.predict(test_dataset)\n",
    "    predictions = np.argmax(test_predictions.predictions, axis=1)\n",
    "    true_labels = test_predictions.label_ids\n",
    "    \n",
    "    # step 3: convert results to a more readable format\n",
    "    readable_results = {}\n",
    "    for key, value in test_results.items():\n",
    "        # Extract the actual metric name from keys like 'eval_accuracy'\n",
    "        if key.startswith('eval_'):\n",
    "            metric_name = key[5:]  # Remove 'eval_' prefix\n",
    "            readable_results[metric_name] = round(value, 4)  # Round to 4 decimal places\n",
    "        else:\n",
    "            readable_results[key] = value\n",
    "    \n",
    "    # step 4: display overall metrics table\n",
    "    overall_metrics = pd.DataFrame({\n",
    "        'Metric': list(readable_results.keys()),\n",
    "        'Value': list(readable_results.values())\n",
    "    })\n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(overall_metrics.set_index('Metric').transpose())\n",
    "    \n",
    "    # step 5: create confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fake\", \"Real\"]).plot(cmap=\"Blues\")\n",
    "    plt.title(\"ISOT Fake News Detection Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # step 6: class-wise performance analysis\n",
    "    class_names = [\"Fake (0)\", \"Real (1)\"]\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_indices = [idx for idx, label in enumerate(true_labels) if label == i]\n",
    "        if len(class_indices) > 0:\n",
    "            class_true = [true_labels[idx] for idx in class_indices]\n",
    "            class_pred = [predictions[idx] for idx in class_indices]\n",
    "            \n",
    "            class_accuracy = accuracy_score(class_true, class_pred)\n",
    "            print(f\"\\n{class_name} class performance:\")\n",
    "            print(f\"  Samples: {len(class_indices)}\")\n",
    "            print(f\"  Accuracy: {class_accuracy:.4f}\")\n",
    "    \n",
    "    return readable_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53515c29-386f-4a22-8bc6-2db86774009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to run the ISOT fake news detection pipeline\n",
    "def run_isot_pipeline(isot_paths=(\"data/isot_dataset/Fake.csv\", \"data/isot_dataset/True.csv\"), n_trials=1):\n",
    "    # step 1: load dataset\n",
    "    train_df, valid_df, test_df = load_isot_dataset(isot_paths)\n",
    "    \n",
    "    # step 2: initialize tokenizer\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    print(f\"\\nInitializing tokenizer for {model_name}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # step 3: create datasets\n",
    "    print(\"Creating PyTorch datasets...\")\n",
    "    train_dataset = FakeNewsDataset(train_df, tokenizer)\n",
    "    valid_dataset = FakeNewsDataset(valid_df, tokenizer)\n",
    "    test_dataset = FakeNewsDataset(test_df, tokenizer)\n",
    "    \n",
    "    # step 4: perform hyperparameter tuning with Optuna\n",
    "    print(\"\\nStarting hyperparameter tuning...\")\n",
    "    best_hparams = tune_hyperparameters(\n",
    "        model_name, \n",
    "        train_dataset, \n",
    "        valid_dataset,\n",
    "        n_trials=n_trials\n",
    "    )\n",
    "    \n",
    "    # step 5: train final model with optimal hyperparameters\n",
    "    print(\"\\nTraining final model with optimal hyperparameters...\")\n",
    "    \n",
    "    # configure training with optimal hyperparameters\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./isot_model\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=best_hparams[\"learning_rate\"],\n",
    "        per_device_train_batch_size=best_hparams[\"batch_size\"],\n",
    "        per_device_eval_batch_size=best_hparams[\"batch_size\"],\n",
    "        num_train_epochs=best_hparams[\"epochs\"],\n",
    "        weight_decay=best_hparams[\"weight_decay\"],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        gradient_accumulation_steps=best_hparams.get(\"gradient_accumulation_steps\", 1)\n",
    "    )\n",
    "    \n",
    "    # initialize model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    # set up early stopping\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=2,\n",
    "        early_stopping_threshold=0.001\n",
    "    )\n",
    "    \n",
    "    # initialize Trainer for final training\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    \n",
    "    # train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # step 6: evaluate model\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    evaluation_metrics = evaluate_model(trainer, test_dataset)\n",
    "    \n",
    "    # step 7: save model\n",
    "    model_path = \"isot_only_model\"\n",
    "    trainer.save_model(model_path)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    print(f\"\\nModel and tokenizer saved to {model_path}\")\n",
    "    \n",
    "    return trainer, evaluation_metrics, best_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5b0105-03bb-4fbd-adbb-6541019522aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ISOT dataset from data/isot_dataset/Fake.csv and data/isot_dataset/True.csv...\n",
      "Applying text preprocessing...\n",
      "ISOT dataset statistics:\n",
      "  Total: 44898 samples\n",
      "  Train: 35918 samples\n",
      "  Valid: 4490 samples\n",
      "  Test: 4490 samples\n",
      "\n",
      "Class distribution:\n",
      "  Overall: {0: 23481, 1: 21417}\n",
      "  Train: {0: 18748, 1: 17170}\n",
      "  Valid: {0: 2348, 1: 2142}\n",
      "  Test: {0: 2385, 1: 2105}\n",
      "\n",
      "Initializing tokenizer for distilbert-base-uncased...\n",
      "Creating PyTorch datasets...\n",
      "\n",
      "Starting hyperparameter tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 07:48:06,852] A new study created in RDB with name: isot_fake_news_detection\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4490' max='4490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4490/4490 08:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.999533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.999787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 07:57:16,459] Trial 0 finished with value: 0.9997666277712952 and parameters: {'learning_rate': 1.827226177606625e-05, 'weight_decay': 0.17254716573280354, 'batch_size': 8, 'epochs': 2, 'gradient_accumulation_steps': 2}. Best is trial 0 with value: 0.9997666277712952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 - F1 Score: 0.9998\n",
      "\n",
      "Optuna hyperparameter tuning complete!\n",
      "Best F1 score: 0.9998\n",
      "Best parameters: {'learning_rate': 1.827226177606625e-05, 'weight_decay': 0.17254716573280354, 'batch_size': 8, 'epochs': 2, 'gradient_accumulation_steps': 2}\n",
      "Could not calculate hyperparameter importance (requires at least 2 completed trials)\n",
      "\n",
      "Top 5 trials:\n",
      "Rank 1: F1=0.9998, Params={'learning_rate': 1.827226177606625e-05, 'weight_decay': 0.17254716573280354, 'batch_size': 8, 'epochs': 2, 'gradient_accumulation_steps': 2}\n",
      "\n",
      "Training final model with optimal hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4490' max='4490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4490/4490 09:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.999787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating final model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Metrics:\n",
      "Metric    loss  accuracy  precision  recall      f1  roc_auc  runtime  \\\n",
      "Value   0.0018    0.9998        1.0  0.9995  0.9998   0.9998  14.9294   \n",
      "\n",
      "Metric  samples_per_second  steps_per_second  epoch  \n",
      "Value               300.75            37.644    2.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fake (0) class performance:\n",
      "  Samples: 2385\n",
      "  Accuracy: 1.0000\n",
      "\n",
      "Real (1) class performance:\n",
      "  Samples: 2105\n",
      "  Accuracy: 0.9995\n",
      "\n",
      "Model and tokenizer saved to isot_only_model\n"
     ]
    }
   ],
   "source": [
    "# run the pipeline \n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate the model\n",
    "    trainer, metrics, best_hparams = run_isot_pipeline()\n",
    "    \n",
    "    # Optionally run the interactive interface\n",
    "    # Uncomment the line below to run the interface after training\n",
    "    # run_interactive_text_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502d59b-5065-4c2f-83c0-a675b91bcee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1e00a-6d74-4305-b682-ab38855aee92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
