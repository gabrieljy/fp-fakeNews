-slide1-
Hello! 

I'm Gabriel, and this is my proposal pitch for my Final Project. 

-slide2-

Before I proceed, please note that I'll be working on the "Fake News Detection" template from the core module CM3060, "Natural Language Processing".

-slide3- 
So, why fake news detection? 

The motivation stems from my understanding that the proliferation of fake news into our society is a dangerously consequential affair, with issues spanning over several disciplines.

-slide4-
Fake news have social consequences. 

For journalism to be trustworthy, journalists must not only be objective, but they must also be perceived to be objective. The rise in misinformation threatens to erase the perception of objectivity, and thus trust - and when people struggle to find means to distinguish truth from a sea of falsehoods, communities are polarised and divided in hostility. 

This social vulnerability can then be exploited further - fake, baseless rumours about a company's fiscal health may crash stock prices to the unfair detriment of investors. 

Misinformation in times of crisis may also cause real harm, as we saw during COVID-19 when Singaporeans panic-bought masks and staple foods in misguided fears of insufficient supply. 

Disinformation campaigns manipulate public opinion, promote political agendas, and undermine elections, creating long-term harm to the democratic process.

More so than ever, people need help to quickly and effectively verify the truthfulness and credibility of information presented to them. 

Thus, I think the production of a fake news detection system that will assist users in distinguishing fact from fiction, and empower them with confidence in the information they consume, is meaningful.

Of course, there has been other work already done to detect fake news.

1. Sample project detecting fake news with Python and Machine Learning provided with the project brief. 

This project exclusively uses a small dataset of 7796 rows that comprises data of unknown origin. 

The size of this dataset is not sufficient for a real-world project as small datasets lack diversity and are insufficient for generalisation to real-world scenarios. Additionally, the provenance of the dataset is unknown, and the source of data contained within is also unknown. 

Additionally, the exclusive reliance on a Passive Aggressive Classifier is way too simple to handle the nuanced language in real-world fake news.

As such, due to those limitations, while this project is effective for the purpose of a simple technical demonstration, a real-world deployment must incorporate larger, more diverse datasets, and a more sophisticated model architecture. 

2. Human-curated fact-checking websites

On platforms like Snopes and PolitiFact, humans manually verify information and inform users if stories are misleading or false. 

While human oversight effectively ensures accuracy, due to the manual effort over time required, it's not suitable to immediately address viral misinformation in real time, nor is it sufficiently scalable to deal with the sheer volume of misinformation available online. This highlights the need for automated systems for their scalability. 

3. "Misleading Content" filters on social media

Social media platforms Facebook and X (formerly Twitter) have introduced automated tools powered by user reports and Artificial Intelligence algorithms to label and limit the reach of misinformation.

These platforms leverage vast datasets to generalise models for large-scale pattern detection, and thus, content flagging. 

However, these systems face criticism for inconsistency and bias, which is further exacerbated when they fail to distinguish between opinion and misinformation. 

Additionally, to limit public backlash, these major social media platforms must balance misinformation prevention against censorship concerns. The general public is aware of these platforms' need to protect their interests, thus the "misleading content" filters are not often perceived as trustworthy. 

4. The LIAR Dataset in conjunction with NLP techniques

Widely used in academic settings, the LIAR dataset contains statements from Politifact, and is used to train machine learning models to detect fake news. 

While it is a foundation for research into fake news detection and has enabled the development of increasingly-accurate NLP models, the LIAR dataset also has limitations due to the relatively small size of the dataset, and its reliance on English data. Many models trained on this dataset struggle to generalise across various different topics and sources. 

As such, the use of limited datasets like LIAR suggest that an effective system needs access to large, cross-domain datasets, and the ability to process data in various languages. 

--

Each of the above solutions demonstrates progress, but also highlights gaps. My project aims to address these gaps.

For scalability and speed, I will use transformer-based models such as BERT that are conducive to my model achieving context-aware language understanding, allowing it to process large volumes of text quickly and accurately.

To address adaptability concerns, my model will be trained on diverse datasets and adversarial training techniques to improve accuracy and to allow for cross-topic generalisation. 

Finally, fostering user-centric trust is a key goal of that will guide my design choices. My solution will provide brief explanations of why content is flagged as a transparency measure rather than simply labeling content, to address the bias and trust issues that current social media filters face. 

--

In summary, my project will build on the foundations of previous fake news detection solutions to create an adaptable system that will foster users' trust and empower them in navigating an overwhelmingly complex information landscape. 

Thank you for your time. 